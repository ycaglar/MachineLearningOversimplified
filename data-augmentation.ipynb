{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ee82c1b",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "The following model is a bean disease classifier utilizing data augmentation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9091d",
   "metadata": {},
   "source": [
    "### Download the necessary data into a colab instance\n",
    "Lines starting with `!` are run as terminal commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, install wget\n",
    "! apt install wget -y\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/ibeans/train.zip \\\n",
    "    -O /tmp/train.zip\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/ibeans/validation.zip \\\n",
    "    -O /tmp/validation.zip\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/ibeans/test.zip \\\n",
    "    -O /tmp/test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d789b39",
   "metadata": {},
   "source": [
    "### Unzip dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/train.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "\n",
    "local_zip = '/tmp/validation.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "\n",
    "local_zip = '/tmp/test.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/test')\n",
    "\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f58c1",
   "metadata": {},
   "source": [
    "### Apply data augmentation to an existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install and import TensorFlow\n",
    "!pip3 install tensorflow\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  rotation_range = 40,\n",
    "  # images will be randomly shift %20 horizontally\n",
    "  width_shift_range = 0.2,\n",
    "  height_shift_range = 0.2,\n",
    "  shear_range = 0.2,\n",
    "  zoom_range = 0.2,\n",
    "  horizontal_flip = True,\n",
    "  fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "validate_datagen = ImageDataGenerator(\n",
    "  rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d34fdbe",
   "metadata": {},
   "source": [
    "### Define data flowers\n",
    "Data flowers will provide data flow from given directories in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d57dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_data_flower = train_datagen.flow_from_directory(\n",
    "  # filepath of the training data\n",
    "  '/tmp/train',\n",
    "  target_size = (224,224),  \n",
    "  batch_size = 128,\n",
    "  #? Since we use `categorical_crossentropy` loss, we need `categorical` labels\n",
    "  class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validate_data_flower = validate_datagen.flow_from_directory(\n",
    "  '/tmp/validation',\n",
    "  target_size = (224,224),  \n",
    "  batch_size = 128,\n",
    "  class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283f8555",
   "metadata": {},
   "source": [
    "### Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c75d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  # The input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "  # 1st convolution\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  # 2nd convolution\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # 3rd convolution\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # 4th convolution\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  # Flatten the results to feed into a DNN\n",
    "  tf.keras.layers.Flatten(),\n",
    "  # 512 neuron hidden layer\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# This will print a summary of your model when you're done!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# certain loss functions and optimizers may work best for certain situations\n",
    "model.compile(\n",
    "  loss = 'categorical_crossentropy',\n",
    "  optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.0001),\n",
    "  metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9908e94",
   "metadata": {},
   "source": [
    "### Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  train_data_flower, \n",
    "  epochs = 8,\n",
    "  verbose = 1,\n",
    "  validation_data = validate_data_flower\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
